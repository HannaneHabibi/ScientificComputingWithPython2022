# -*- coding: utf-8 -*-
"""ScientificcomputationEx08.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HMiFFcrE47wG1x-itki4iwOH6oB87cnz

Exercise 1
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy import linalg as la
import seaborn as sns
import pandas as pd

x1 = np.random.normal(0, 1, 1000)
x2=x1+np.random.normal(0, 3, 1000)
x3=2*x1+x2

df=np.array([x1,x2,x3])
np_cov = np.cov(df)
print(np_cov.shape)
print(np_cov)

print("x1 and x2")
sns.scatterplot(x1, x2);

print("x1 and x3")
sns.scatterplot(x1, x3);

print("x2 and x3")
sns.scatterplot(x2, x3);

U, S, Vt = np.linalg.svd(df)
scale_factor = 3
print(U)
print(S**2/(1000-1))

value, vector = la.eig(np_cov)
real = np.real_if_close(value)
print('eigenvalues using the eigendecomposition of the covariance matrix')
print(value)
print('\nrealeigenvalues using the eigendecomposition of the covariance matrix')
print(real)
print('\neigenvectors using the eigendecomposition of the covariance matrix')
print(vector)

""" eigenvectors and eigenvalues using the SVD:

"""

U, s, Vt = la.svd(np_cov)
print('u:',U)
print(np.real_if_close(s))
print('\ns:',s, "\n")
print(vector,"\n")
print(vector.T.shape)

print(value,"\n")
print(s,"\n")
Lambda = np.diag(value)
print(Lambda,"\n")
print(Lambda.trace(),"\n")
print(np_cov.trace(),"\n")

print("First axes for pca:",Lambda[0][0]/np_cov.trace(),"\n")
print("second axes for pca:",Lambda[0][0]/Lambda.trace())

la=np.diag(s)
ax = plt.axes(projection='3d')
scale_factor = 3
plt.rcParams['figure.figsize'] = (8,8)
ax.scatter(x1, x2, x3, s=100);

for val, vec in zip(value,vector.T):
    print("Eigenvalue:", val, "\neigenvector:", vec,"\nsld:",vec[0],"\n")
    plt.plot([0, scale_factor * val * vec[0]], [0, scale_factor * val * vec[1]],
             [0, scale_factor * val * vec[2]], 'g-')

lsvd = S**2/(1000-1)
Vsvd = U
ax = plt.axes(projection='3d')
scale_factor = 3
plt.rcParams['figure.figsize'] = (8,8)
ax.scatter(x1, x2, x3, s=100);

for val, vec in zip(lsvd,Vsvd.T ):
    print("Eigenvalue:", val, ",\neigenvector:", vec,"\nsld:",vec[0],"\n")
    plt.plot([0, scale_factor * val * vec[0]], [0, scale_factor * val * vec[1]],
             [0, scale_factor * val * vec[2]], 'g-')

Xp = np.dot(vector.T, df)
scale_factor=6
plt.rcParams['figure.figsize'] = (8,8)
ax = plt.axes(projection='3d')

ax.scatter(Xp[0,:], Xp[1,:],Xp[2,:], alpha=0.1,s=100)
for val, vec in zip(lsvd,Vsvd.T):
    print("Eigenvalue:", val, ",\neigenvector:", vec,"\nsld:",vec[0], "\n")
    plt.plot([0, scale_factor * val * vec[0]], [0, scale_factor * val * vec[1]],[0, scale_factor * val * vec[2]], 'g-')

new_ds=np.dot(vector.T, df)
fig, axes = plt.subplots(2, 3, figsize=(15,15))
axes[0,0].scatter(df[0],df[1] ,alpha=0.4)
axes[0,1].scatter(df[0],df[2] ,alpha=0.4)
axes[0,2].scatter(df[1],df[2] ,alpha=0.4)
axes[1,0].scatter(new_ds[0],new_ds[1] ,color="g",alpha=0.6)
axes[1,1].scatter(new_ds[0],new_ds[2] ,color="g",alpha=0.6)
axes[1,2].scatter(new_ds[1],new_ds[2] ,color="g",alpha=0.6)

"""Exercise 3"""

# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data -P data/
# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.names -P data/ 
dataset = pd.read_csv("data/magic04.data",header = None)

dataset=dataset.iloc[:,:10] 
covariance = dataset.cov()

l, v = la.eig(covariance)
l = np.real_if_close(l)
xp = np.dot(v.T,dataset.T)

fig, axs = plt.subplots(2,3,figsize=(32,15))
axs[0][0].set_title("x0 vs x1")
axs[0][0].scatter(dataset.iloc[:,0],dataset.iloc[:,1])
axs[0][1].set_title("x0 vs x2")
axs[0][1].scatter(dataset.iloc[:,0],dataset.iloc[:,2])
axs[0][2].set_title("x1 vs x2")
axs[0][2].scatter(dataset.iloc[:,1],dataset.iloc[:,2])

axs[1][0].set_title("xpca0 vs xpca1")
axs[1][0].scatter(xp[0,:],xp[1,:])
axs[1][1].set_title("xpca0 vs xpca2")
axs[1][1].scatter(xp[0,:],xp[2,:])
axs[1][2].set_title("xpca1 vs xpca2")
axs[1][2].scatter(xp[1,:],xp[2,:])

file_name="/content/data/magic04.data"
head="/content/data/magic04.names"
df=pd.read_csv(file_name, names=["fLength","fWidth","fSize","fConc","fConc1","fAsym","fM3Long","fM3Trans","fAlpha","fDist"])
cov_m=np.cov(df.iloc[:,:-2].T)
l, V = la.eig(cov_m)

dataPCA=np.dot(V.T, df.iloc[:,:-2].T)

dataPCA